{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CTR Predictor basics\n",
    "--------------------\n",
    "This is a very simple tutorial that covers creating/using CTR predictor based on two features (Domain, OS), loading model in your code, and predicting CTR in your code. \n",
    "\n",
    "Prediction step of some of the ML models are very trivial (find a sum, apply a simple formula). Using third-party libraries/services can have a lot of overhead (jni,  serialization/deserialization, running 3p daemons, and, most enjoyable, debugging 3rd-party daemons under high load). And making inference inside of your app makes a lot of sense. \n",
    "\n",
    "I also describe how to do feature encoding in a convenient way from the point of software engineering, and how to make sure that there is no magic. \n",
    "\n",
    "What's not covered here is a choice of features and creation of a new ones (features). I also didn't cover negative downsampling (which typically allows to handle 100x less data). \n",
    "\n",
    "Let's load some libs, and some data (data in a table format: domain, OS, and wether there was or there was no click)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mmh3\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 igworx  staff  106166469 Dec 30 14:54 ctr_dataset.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -ltr *.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('ctr_dataset.json').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Domain</th>\n",
       "      <th>OS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HappyGoodall.com</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ZealousLamport.com</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>DazzlingPike.com</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>HopefulHawking.com</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>VibrantHeisenberg.com</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Clicks                 Domain       OS\n",
       "0      0       0       HappyGoodall.com  Android\n",
       "1      1       0     ZealousLamport.com  Windows\n",
       "2     10       0       DazzlingPike.com  Windows\n",
       "3    100       0     HopefulHawking.com  Android\n",
       "4   1000       0  VibrantHeisenberg.com  Windows"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clicks: 15623\n",
      "Total lines: 1747637\n"
     ]
    }
   ],
   "source": [
    "print 'Total clicks:', df.Clicks.sum()\n",
    "print 'Total lines:', len(df.Clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CTR in a dataset 0.00893949944983\n"
     ]
    }
   ],
   "source": [
    "print 'Average CTR in a dataset', df.Clicks.sum()/float(len(df.Clicks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm making train/test split by assigning *first 80%* of lines to train, and *the last 20%* to test set (assuming they are sorted by timestamps).\n",
    "This way, test set performance will be a better indication of how predictor will fare in prod, since test set might contain new values of categorical variables, that were not seen before. \n",
    "\n",
    "My recommendation, when you develop basic predictors in adtech, to not do a random split, since that will leak future information to the predictor. (Obvious, but just in case.) Another painfully obvious thing is that you can safely shuffle train/test sets after a split. \n",
    "\n",
    "Logistic regression inference is very simple:\n",
    "\n",
    "$Å· = Sigmoid ( a_0x_0 + a_1x_1 + ... a_nx_n +b )$\n",
    "\n",
    "Where Simoid is simply a function we use to map values to the interval from 0 to 1: \n",
    "$Sigmoid(x) = \\frac{1}{1+e^{-x}}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x159da25d0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x147e07510>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1./(1.+np.exp(-x))\n",
    "\n",
    "x = np.linspace(-8.,8.,100)\n",
    "plt.plot(x,sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $x_1, x_2, .. x_n$ would only take values of zero and one, it'll make our lives much easier when we'll predict something: because if $x_n$ is 0, weights don't matter. And inference step becomes trivial: we simply sum up weights for non-zero features, and apply sigmoid function.\n",
    "\n",
    "Now, how do we go from  a table  to a list of bit strings?\n",
    "\n",
    "| Domain | OS |\n",
    "|------|------|\n",
    "| example1.com | Desktop | \n",
    "| exmple2.com | Desktop | \n",
    "| exmple3.com | Desktop | \n",
    "| exmple3.com | Mobile | \n",
    "\n",
    "\n",
    "Simple thing to do is to use dummy encoding, by encoding every value of categorical variable (e.g. domain name) into it's own integer value. For example: \n",
    "Domain_example1.com -> 0\n",
    "Device_type_Desktop -> 1\n",
    "Domain_example2.com -> 2\n",
    "Domain_example3.com -> 3\n",
    "Device_type_Mobile -> 4\n",
    "\n",
    "And this way, we can represent our table as a list of bit strings:\n",
    "\n",
    "| Domain | OS | Encoded |\n",
    "|------|------|------| \n",
    "| example1.com | Desktop | 00011 |\n",
    "| exmple2.com | Desktop | 00101 | \n",
    "| exmple3.com | Desktop | 01001 |\n",
    "| exmple3.com | Mobile |  11000 |\n",
    "\n",
    "When we have a lot of possible values e.g. 1m different domain, and one million bits, with just two set on every line. This line 000000000100000000100 can be come very sparse. And the easiest way to encode sparce bit array is simply by listing indices of non-zero elements.  \n",
    "\n",
    "| Domain | OS | Encoded | Set bit indices |\n",
    "|------|------|------|------|\n",
    "| example1.com | Desktop | 00011 | 0,1| \n",
    "| exmple2.com | Desktop | 00101 | 0,2|\n",
    "| exmple3.com | Desktop | 01001 | 0,3|\n",
    "| exmple3.com | Mobile |  11000 | 3,4|\n",
    "\n",
    "\n",
    "That'll work. However, most of the time we don't really care about having backward mapping of features (from indices to their names), and we simply can hash features into a really big space (like, 2^22-2^26...). \n",
    "\n",
    "It's like a hash table with a table size we define on start, and the values are either 0 or 1. If space (table size) is sufficiently large, and the hash function works well, the collisions are rare. \n",
    "\n",
    "And even when there are collisions, it only improves model generalization. \n",
    "\n",
    "This obviously cannot be called anything else but hashing trick. \n",
    "\n",
    "VW does its own hashing trick (using one of murmurhash version); but for a better control over hash func we'll prepare data ourselves. \n",
    "\n",
    "VW also has a magical value for a constant (intercept), but to make sure there is no magic, we'll have a special id (const)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = 2**24 # our space\n",
    "mod = space - 1 # but we won't use one value, because we want to have place for intercept\n",
    "const = mod "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's hash individual variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Domain_hash'] = df.Domain.apply(lambda x: (mmh3.hash(\"domain_\"+x, signed=False) % mod))\n",
    "df['OS_hash'] = df.OS.apply(lambda x: (mmh3.hash(\"hash_\"+x, signed=False) % mod))\n",
    "df['Intersection_hash'] = df.apply(lambda x: mmh3.hash(\"intersection_%s_%s\" % (x.Domain, x.OS), signed=False) % mod, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's generate data in VW format. If you are going to use pipeline similar to described here, I encourage you to handle the format string with care (spaces matter). \n",
    "\n",
    "The format, simplified, is as following:\n",
    "\n",
    "label | feature1 feature2 feature3 ... \n",
    "\n",
    "The \"features\" that we feed into VW, are simply indices for our non-zero features. \n",
    "The label is \"1\" for positive example (click), and \"-1\" for negative example: the absence of a click."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clicks=[\"-1\",\"1\"]\n",
    "def VowpalWabbitFormat(x):\n",
    "    return \"%s | %d %d %d %d\" % (clicks[x.Clicks], x.Domain_hash, x.OS_hash, x.Intersection_hash, const)\n",
    "\n",
    "df['VW'] = df.apply(VowpalWabbitFormat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Domain</th>\n",
       "      <th>OS</th>\n",
       "      <th>Domain_hash</th>\n",
       "      <th>OS_hash</th>\n",
       "      <th>Intersection_hash</th>\n",
       "      <th>VW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HappyGoodall.com</td>\n",
       "      <td>Android</td>\n",
       "      <td>12233527</td>\n",
       "      <td>2670727</td>\n",
       "      <td>16026914</td>\n",
       "      <td>-1 | 12233527 2670727 16026914 16777215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ZealousLamport.com</td>\n",
       "      <td>Windows</td>\n",
       "      <td>2155948</td>\n",
       "      <td>5721293</td>\n",
       "      <td>7606037</td>\n",
       "      <td>-1 | 2155948 5721293 7606037 16777215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>DazzlingPike.com</td>\n",
       "      <td>Windows</td>\n",
       "      <td>7552272</td>\n",
       "      <td>5721293</td>\n",
       "      <td>14139854</td>\n",
       "      <td>-1 | 7552272 5721293 14139854 16777215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>HopefulHawking.com</td>\n",
       "      <td>Android</td>\n",
       "      <td>6885255</td>\n",
       "      <td>2670727</td>\n",
       "      <td>16441169</td>\n",
       "      <td>-1 | 6885255 2670727 16441169 16777215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>VibrantHeisenberg.com</td>\n",
       "      <td>Windows</td>\n",
       "      <td>3384234</td>\n",
       "      <td>5721293</td>\n",
       "      <td>7935879</td>\n",
       "      <td>-1 | 3384234 5721293 7935879 16777215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Clicks                 Domain       OS  Domain_hash  OS_hash  \\\n",
       "0      0       0       HappyGoodall.com  Android     12233527  2670727   \n",
       "1      1       0     ZealousLamport.com  Windows      2155948  5721293   \n",
       "2     10       0       DazzlingPike.com  Windows      7552272  5721293   \n",
       "3    100       0     HopefulHawking.com  Android      6885255  2670727   \n",
       "4   1000       0  VibrantHeisenberg.com  Windows      3384234  5721293   \n",
       "\n",
       "   Intersection_hash                                       VW  \n",
       "0           16026914  -1 | 12233527 2670727 16026914 16777215  \n",
       "1            7606037    -1 | 2155948 5721293 7606037 16777215  \n",
       "2           14139854   -1 | 7552272 5721293 14139854 16777215  \n",
       "3           16441169   -1 | 6885255 2670727 16441169 16777215  \n",
       "4            7935879    -1 | 3384234 5721293 7935879 16777215  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Vowpal Wabbit here for stability and effectiveness of their SGD implementation. This is almost perfect tool for first take on production-ready ML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[0:int(len(df)*0.8)]\n",
    "test = df[int(len(df)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008892010565699814"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_train_ctr = float(train.Clicks.sum())/float(len(train))\n",
    "mean_train_ctr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving data in VW format to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.VW.to_csv('train.vw', header=False, index=False)\n",
    "test.VW.to_csv('test.vw', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train VW! \n",
    "\n",
    "| Parameter | Description   |\n",
    "|------|------|\n",
    "|  -f    | model filename |\n",
    "|  --readable_model    | readable model filename |\n",
    "|  --loss_function    |  loss function for learning (in our case, logistic regression)  |\n",
    "|  --hash strings   |  we only hash features that look like strings; everything numeric presumed to be already hashed  |\n",
    "| -b | our hashing space |\n",
    "| --noconstant | do not use intercept: otherwise VW will add intercept at a magical index |  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 24\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.693147 0.693147            1            1.0  -1.0000   0.0000        4\n",
      "0.646099 0.599051            2            2.0  -1.0000  -0.1980        4\n",
      "0.545920 0.445742            4            4.0  -1.0000  -0.6257        4\n",
      "0.448676 0.351432            8            8.0  -1.0000  -0.6945        4\n",
      "0.332870 0.217064           16           16.0  -1.0000  -1.5828        4\n",
      "0.236141 0.139411           32           32.0  -1.0000  -2.1487        4\n",
      "0.152060 0.067980           64           64.0  -1.0000  -2.8825        4\n",
      "0.095498 0.038935          128          128.0  -1.0000  -4.2980        4\n",
      "0.108724 0.121950          256          256.0  -1.0000  -3.4444        4\n",
      "0.078629 0.048534          512          512.0  -1.0000  -5.6540        4\n",
      "0.059955 0.041282         1024         1024.0  -1.0000  -5.8409        4\n",
      "0.048356 0.036756         2048         2048.0  -1.0000  -6.2759        4\n",
      "0.055138 0.061921         4096         4096.0  -1.0000  -4.8464        4\n",
      "0.051236 0.047334         8192         8192.0  -1.0000  -6.3709        4\n",
      "0.052339 0.053442        16384        16384.0  -1.0000  -6.3334        4\n",
      "0.049019 0.045700        32768        32768.0  -1.0000  -5.0551        4\n",
      "0.046363 0.043707        65536        65536.0  -1.0000  -7.6793        4\n",
      "0.044493 0.042622       131072       131072.0  -1.0000  -9.1019        4\n",
      "0.043280 0.042068       262144       262144.0  -1.0000  -4.3918        4\n",
      "0.043255 0.043229       524288       524288.0  -1.0000  -4.3245        4\n",
      "0.042688 0.042122      1048576      1048576.0  -1.0000  -3.4987        4\n",
      "\n",
      "finished run\n",
      "number of examples = 1398109\n",
      "weighted example sum = 1398109.000000\n",
      "weighted label sum = -1373245.000000\n",
      "average loss = 0.043239\n",
      "best constant = -4.713670\n",
      "best constant's loss = 0.050846\n",
      "total feature number = 5592436\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "!rm model.vw\n",
    "!rm model.txt\n",
    "!vw train.vw -f model.vw --readable_model model.txt --loss_function logistic --hash strings -b 24 --noconstant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 8.7.0\r\n",
      "Id \r\n",
      "Min label:-50\r\n",
      "Max label:50\r\n",
      "bits:24\r\n",
      "lda:0\r\n",
      "0 ngram:\r\n",
      "0 skip:\r\n",
      "options: --hash strings\r\n",
      "Checksum: 428910861\r\n",
      ":0\r\n",
      "1252:-1.04228\r\n",
      "4893:-1.61656\r\n",
      "10593:-0.510001\r\n",
      "13163:0.0826358\r\n",
      "16809:-1.85865\r\n",
      "19229:-1.43742\r\n",
      "20317:-1.54855\r\n",
      "23551:-0.751467\r\n",
      "23782:-0.73655\r\n"
     ]
    }
   ],
   "source": [
    "!head -n20 model.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test.apply(lambda x: [x.Domain_hash,x.OS_hash, x.Intersection_hash], axis=1)\n",
    "X_test = X_test.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is predictor implementation sans error checks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionPredictor:\n",
    "    def __init__(self, space, const):\n",
    "        self.space = space\n",
    "        self.const = const\n",
    "        self.weights=np.zeros(space)\n",
    "        \n",
    "    def load_model(self, filename):\n",
    "        text_model = open(filename)\n",
    "        k = 0\n",
    "        for i,l in enumerate(text_model):\n",
    "            if i<11: # we simply pray that we don't need first 10 lines \n",
    "                continue\n",
    "            k+=1\n",
    "            w = l.strip().split(':')\n",
    "            self.weights[int(w[0])]= float(w[1])\n",
    "        text_model.close()\n",
    "        \n",
    "    #features: array of arrays, w/o const, we'll add it in\n",
    "    def predict(self, X):\n",
    "        y_hat = []\n",
    "        for features in X:\n",
    "            s = self.weights[const]\n",
    "            for f in features:\n",
    "                s+= self.weights[f]\n",
    "            r = sigmoid(s)\n",
    "            y_hat.append(r)\n",
    "        return y_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a model from file on disk, and make our predcitions for the test split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionPredictor(space, const)\n",
    "lr.load_model('model.txt')\n",
    "preds_loaded_model = lr.predict(X_test)\n",
    "preds_loaded_model = pd.DataFrame({'preds_internal': preds_loaded_model})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make predictions with vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = preds.txt\n",
      "Num weight bits = 24\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.007766 0.007766            1            1.0  -1.0000   0.0077        4\n",
      "0.005835 0.003904            2            2.0  -1.0000   0.0039        4\n",
      "0.006280 0.006725            4            4.0  -1.0000   0.0014        4\n",
      "0.008947 0.011615            8            8.0  -1.0000   0.0002        4\n",
      "0.006260 0.003573           16           16.0  -1.0000   0.0047        4\n",
      "0.007259 0.008259           32           32.0  -1.0000   0.0233        4\n",
      "0.005987 0.004715           64           64.0  -1.0000   0.0003        4\n",
      "0.009460 0.012932          128          128.0  -1.0000   0.0001        4\n",
      "0.009815 0.010171          256          256.0  -1.0000   0.0001        4\n",
      "0.015831 0.021847          512          512.0  -1.0000   0.0154        4\n",
      "0.041109 0.066387         1024         1024.0  -1.0000   0.0289        4\n",
      "0.040156 0.039202         2048         2048.0  -1.0000   0.0019        4\n",
      "0.039101 0.038046         4096         4096.0  -1.0000   0.0000        4\n",
      "0.040033 0.040966         8192         8192.0  -1.0000   0.0007        4\n",
      "0.042969 0.045906        16384        16384.0  -1.0000   0.0029        4\n",
      "0.043397 0.043825        32768        32768.0  -1.0000   0.0260        4\n",
      "0.042737 0.042076        65536        65536.0  -1.0000   0.0019        4\n",
      "0.042542 0.042348       131072       131072.0  -1.0000   0.0094        4\n",
      "0.043650 0.044757       262144       262144.0  -1.0000   0.0039        4\n",
      "\n",
      "finished run\n",
      "number of examples = 349528\n",
      "weighted example sum = 349528.000000\n",
      "weighted label sum = -343146.000000\n",
      "average loss = 0.043879\n",
      "best constant = -4.687078\n",
      "best constant's loss = 0.051962\n",
      "total feature number = 1398112\n"
     ]
    }
   ],
   "source": [
    "!vw test.vw -t -i model.vw  --loss_function logistic --hash strings -b 24 --noconstant --link=logistic -p preds.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load VW's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_vw = pd.read_csv('preds.txt', names=['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({\n",
    " 'Clicks': test.Clicks.values,\n",
    " 'PredsVW': preds_vw.preds,\n",
    " 'PredsInt': preds_loaded_model.preds_internal\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's make sure that they are exactly the same as what we predicted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiffDueToMagic 2.45360775203e-07\n"
     ]
    }
   ],
   "source": [
    "DiffDueToMagic = (res.PredsInt-res.PredsVW).abs().sum()/float(len(res))\n",
    "print \"DiffDueToMagic\", DiffDueToMagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is a VERY small value. Let's now calculate the average CTRs for baseline predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_ctr = train.groupby('Domain_hash')['Clicks'] .agg(('count', 'size', 'mean', 'sum')).reset_index()\n",
    "OS_ctr = train.groupby('OS_hash')['Clicks'] .agg(('count', 'size', 'mean', 'sum')).reset_index()\n",
    "intersection_ctr = train.groupby('Intersection_hash')['Clicks'] .agg(('count', 'size', 'mean', 'sum')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain_hash</th>\n",
       "      <th>count</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4893</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10593</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19229</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23551</td>\n",
       "      <td>647</td>\n",
       "      <td>647</td>\n",
       "      <td>0.026275</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23782</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Domain_hash  count  size      mean  sum\n",
       "0         4893     45    45  0.000000    0\n",
       "1        10593     67    67  0.044776    3\n",
       "2        19229     23    23  0.000000    0\n",
       "3        23551    647   647  0.026275   17\n",
       "4        23782     13    13  0.076923    1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_ctr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets make predictions using our esitmators, and put it into a single table for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(tbl, column_name, val):\n",
    "    l = tbl[tbl[column_name]==val]['mean'].values.tolist()\n",
    "    if len(l)==0:\n",
    "        return mean_train_ctr\n",
    "    return l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr_pred_by_domain = test.apply(lambda x: lookup(domain_ctr, 'Domain_hash', x.Domain_hash) ,axis=1).values\n",
    "ctr_pred_by_intersect = test.apply(lambda x: lookup(intersection_ctr, 'Intersection_hash', x.Intersection_hash) ,axis=1).values\n",
    "ctr_pred_by_device_type = test.apply(lambda x: lookup(OS_ctr, 'OS_hash', x.OS_hash) ,axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame({\n",
    " 'Clicks': test.Clicks.values,\n",
    " 'PredsVW': preds_vw.preds,\n",
    " 'PredsInt': preds_loaded_model.preds_internal,\n",
    " 'PredsDomain': ctr_pred_by_domain,\n",
    " 'PredsOS': ctr_pred_by_device_type,    \n",
    " 'PredsIntersect': ctr_pred_by_intersect\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clicks</th>\n",
       "      <th>PredsDomain</th>\n",
       "      <th>PredsInt</th>\n",
       "      <th>PredsIntersect</th>\n",
       "      <th>PredsOS</th>\n",
       "      <th>PredsVW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>0.007735</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>0.007735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.003896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.011956</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.011956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>0.001420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.020356</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.020356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clicks  PredsDomain  PredsInt  PredsIntersect   PredsOS   PredsVW\n",
       "0       0     0.006774  0.007735        0.006774  0.006263  0.007735\n",
       "1       0     0.003254  0.003896        0.003254  0.011643  0.003896\n",
       "2       0     0.010139  0.011956        0.010139  0.011643  0.011956\n",
       "3       0     0.001031  0.001420        0.001031  0.006263  0.001420\n",
       "4       0     0.016148  0.020356        0.016148  0.011643  0.020356"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's look at predictor performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: PredsDomain ROC AUC: 0.818966, Log Loss: 0.056889, Err: 0.028590, RMSE: 0.093805\n",
      "Pred: PredsInt ROC AUC: 0.838927, Log Loss: 0.043879, Err: -0.049233, RMSE: 0.093592\n",
      "Pred: PredsIntersect ROC AUC: 0.818966, Log Loss: 0.056889, Err: 0.028590, RMSE: 0.093805\n",
      "Pred: PredsOS ROC AUC: 0.573714, Log Loss: 0.051688, Err: 0.025731, RMSE: 0.095077\n"
     ]
    }
   ],
   "source": [
    "for pred_source in ['PredsDomain', 'PredsInt', 'PredsIntersect', 'PredsOS']:\n",
    "    roc_auc = roc_auc_score(res.Clicks, res[pred_source])\n",
    "    ll = log_loss(res.Clicks, res[pred_source])\n",
    "    err = (res.Clicks.sum() - res[pred_source].sum())/res.Clicks.sum()\n",
    "    rmse = np.sqrt(np.power((res.Clicks-res[pred_source]),2).sum()/float(len(res.Clicks)))\n",
    "    print \"Pred: %s ROC AUC: %f, Log Loss: %f, Err: %f, RMSE: %f\" % ( pred_source, roc_auc, ll, err, rmse )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main conclusion I draw here is that test data could much more illustrating that that. \n",
    "\n",
    "But there are a couple of interesting results: first, it's clear that OS is quite useless. \n",
    "\n",
    "And logistic regression outperofrms simple domain-based CTR estimator, as well as estimator that is based on two variables. With increase in a number of variables and amount of data, it'll do much better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
